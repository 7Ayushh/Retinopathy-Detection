{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from zipfile import ZipFile\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import argparse"
      ],
      "metadata": {
        "id": "6MCT2MxOB4oQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making the directories\n",
        "os.system('rm -rf data && mkdir data')\n",
        "os.system('rm -rf data/Mild && mkdir data/Mild')\n",
        "os.system('rm -rf data/Severe && mkdir data/Severe')\n",
        "os.system('rm -rf data/No_DR && mkdir data/No_DR')\n",
        "os.system('rm -rf data/Moderate && mkdir data/Moderate')\n",
        "os.system('rm -rf data/Proliferate && mkdir data/Proliferate')\n",
        "\n",
        "os.system('rm -rf testdata && mkdir testdata')\n",
        "os.system('rm -rf testdata/Mild && mkdir testdata/Mild')\n",
        "os.system('rm -rf testdata/Severe && mkdir testdata/Severe')\n",
        "os.system('rm -rf testdata/No_DR && mkdir testdata/No_DR')\n",
        "os.system('rm -rf testdata/Moderate && mkdir testdata/Moderate')\n",
        "os.system('rm -rf testdata/Proliferate && mkdir testdata/Proliferate')\n",
        "# if you have more than 2 classes then make the directories as per use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALHVZq3kC4gT",
        "outputId": "b306b215-6978-4a22-b00b-2a820bdb57dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class ResidualBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "#         super(ResidualBlock, self).__init__()\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#                         nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "#                         nn.BatchNorm2d(out_channels),\n",
        "#                         nn.ReLU())\n",
        "#         self.conv2 = nn.Sequential(\n",
        "#                         nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "#                         nn.BatchNorm2d(out_channels))\n",
        "#         self.downsample = downsample\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.out_channels = out_channels\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         residual = x\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.conv2(out)\n",
        "#         if self.downsample:\n",
        "#             residual = self.downsample(x)\n",
        "#         out += residual\n",
        "#         out = self.relu(out)\n",
        "#         return out"
      ],
      "metadata": {
        "id": "SOxkfWCxfAEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# class ResNet(nn.Module):\n",
        "#     def __init__(self, block, layers, num_classes = 10):\n",
        "#         super(ResNet, self).__init__()\n",
        "#         self.inplanes = 64\n",
        "#         self.conv1 = nn.Sequential(\n",
        "#                         nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "#                         nn.BatchNorm2d(64),\n",
        "#                         nn.ReLU())\n",
        "#         self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "#         self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
        "#         self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
        "#         self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
        "#         self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
        "#         self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "#         self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "#     def _make_layer(self, block, planes, blocks, stride=1):\n",
        "#         downsample = None\n",
        "#         if stride != 1 or self.inplanes != planes:\n",
        "            \n",
        "#             downsample = nn.Sequential(\n",
        "#                 nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "#                 nn.BatchNorm2d(planes),\n",
        "#             )\n",
        "#         layers = []\n",
        "#         layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "#         self.inplanes = planes\n",
        "#         for i in range(1, blocks):\n",
        "#             layers.append(block(self.inplanes, planes))\n",
        "\n",
        "#         return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.maxpool(x)\n",
        "#         x = self.layer0(x)\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "\n",
        "#         x = self.avgpool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         print(x.shape)\n",
        "#         x = self.fc(x)\n",
        "\n",
        "#         return x"
      ],
      "metadata": {
        "id": "fGQ3XMX2fH3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_classes = 10\n",
        "# num_epochs = 20\n",
        "# batch_size = 16\n",
        "# learning_rate = 0.01\n",
        "\n",
        "# net = ResNet(ResidualBlock, [3, 4, 6, 3])\n",
        "\n",
        "# # Loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9) "
      ],
      "metadata": {
        "id": "H2FZpalngJiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3, padding='same')\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3, padding='same')\n",
        "        self.fc1 = nn.Linear(50176, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #print(x.shape)\n",
        "        x = torch.flatten(x, 1)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "# this is the model"
      ],
      "metadata": {
        "id": "TpwJbMekC-Gy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4901, 0.4617, 0.4061], [0.1977, 0.1956, 0.1947])\n",
        "])\n",
        "\n",
        "data = torchvision.datasets.ImageFolder(\n",
        "    root='data',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "classes = data.classes\n",
        "dataloader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "ETccLWAfFtgQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('model.pt'):\n",
        "    print('----> loaded pretrained model')\n",
        "    net.load_state_dict(torch.load('model.pt'))"
      ],
      "metadata": {
        "id": "EasiyF-1Fyyi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "print(f'----> starting training for {num_epochs} epochs')\n",
        "\n",
        "with tqdm(range(num_epochs), desc='training') as training_bar:\n",
        "    for epoch in training_bar:\n",
        "        running_loss = 0.0\n",
        "        epoch_bar = tqdm(enumerate(dataloader), desc=f'epoch {epoch + 1}')\n",
        "        for i, data in epoch_bar:\n",
        "            inputs, labels = data\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            epoch_bar.set_postfix(average_running_loss=running_loss / (i + 1))\n",
        "\n",
        "print('----> finished training')\n"
      ],
      "metadata": {
        "id": "YtFmyNBVG6hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = torchvision.datasets.ImageFolder(\n",
        "    root='testdata',\n",
        "    transform=transform\n",
        ")\n",
        "testdataloader = torch.utils.data.DataLoader(testdata, batch_size=32, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "uv7_Dp0uNRcQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for testdata in testdataloader:\n",
        "        inputs, labels = testdata\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'----> accuracy on the dataset: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "id": "Q-Gkie2hG7I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6ba8f6-a5f9-4be0-ee65-1f98e391880a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----> accuracy on the dataset: 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----> saving model to model.pt')\n",
        "\n",
        "torch.save(net.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "1cG37uFmG9iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3d84ef-5c92-4efc-c78e-902253a09081"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----> saving model to model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_Ut38_1Ns11"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}